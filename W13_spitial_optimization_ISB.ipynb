{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook shows the full spatial optimization pipeline. Starting with hypercube construction, MSFA sampling, demosaicing, and finally conversion to RGB true color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from scipy.signal import convolve2d\n",
    "import pandas as pd\n",
    "from itertools import permutations \n",
    "\n",
    "from pysptools import abundance_maps\n",
    "import numpy\n",
    "from random import sample as randsamp\n",
    "import random\n",
    "import urllib\n",
    "import itertools\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sythentic_hypercube(a_map, spectra, wavelength):\n",
    " \n",
    "    '''\n",
    "    Encodes a 2d image with spectral data to generate a synthetic hypercube.\n",
    "    \n",
    "    Inputs:\n",
    "        a_map (N x M x L array) - 3D abundance map of target. Each channel in L corresponds to the\n",
    "             abundance (between 0 and 1) of the spectral signature in the spectra array. \n",
    "             \n",
    "        spectra (L x Q array) - Array of 1D spectral respones for each pixel. Number of array members\n",
    "            should be equal to the maximum value in im (L). Q is sample points in wavelength space.\n",
    "            \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            response arrays.\n",
    "    \n",
    "    Output:\n",
    "        hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            dimension of the hypercube.\n",
    "    '''\n",
    "\n",
    "    N,M,_ = a_map.shape\n",
    "    L,Q = spectra.shape\n",
    "\n",
    "    hypercube = zeros((N,M,Q))\n",
    "\n",
    "    for i in range(L):\n",
    "        hypercube += outer(a_map[:,:,i],spectra[i]).reshape((N,M,Q))\n",
    "\n",
    "    return hypercube, wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlation_matrix(hypercube, filter_responses, wavelength, verbose=False):\n",
    "    '''\n",
    "    Function to generate the correlation matrix between different\n",
    "    channels in the MSFA. Computes the correlation between the central \n",
    "    wavelengths of each filter for every unique spectral response\n",
    "    found in the target. Then, takes a weighted average of these\n",
    "    correlations depending on how prevalent the particular spectral\n",
    "    response is. Correlation matrix should be calculated before\n",
    "    noise is added to the system.\n",
    "    \n",
    "    Inputs:\n",
    "        hypercube (N x M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        filter_responses (J x Q) - Normalized (max of 1) spectral response curves, or QE curves, for each \n",
    "            filter in the MSFA. A total of J different filter responses of the macropixel\n",
    "            should be provided in reading order. J will equal the number of sub-pixels in the macro-pixel.\n",
    "            e.g., px*py = J. Even if there is a duplicate filter, provide the same spectral response curve.\n",
    "            \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            dimension of the hypercube. Filter spectral responses must also be provided on this axis.\n",
    "        \n",
    "        verbose (optional Boolean, default=False) - Set to true to get updates on processing\n",
    "        \n",
    "    Outputs:\n",
    "        corr (J x J) - Correlation matrix between central wavelengths \n",
    "    '''\n",
    "    \n",
    "    # Normalize spectral data per pixel to \n",
    "    N,M,Q = hypercube.shape\n",
    "    hsi_norm = hypercube.max(axis=2)\n",
    "    hsi_norm[hsi_norm==0] = 1.\n",
    "\n",
    "    responses = []\n",
    "    num_responses = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if verbose and not i%100:\n",
    "            print('Processing Row %d' %i)\n",
    "        for j in range(M):\n",
    "            norm_sig = hypercube[i,j]/hsi_norm[i,j]\n",
    "            index_array = [all(norm_sig == resp) for resp in responses]\n",
    "            if any(index_array):\n",
    "                num_responses[argmax(index_array)]+=1\n",
    "                continue\n",
    "            else:\n",
    "                responses.append(norm_sig)\n",
    "                num_responses.append(1)\n",
    "                \n",
    "    filter_maxima = [argmax(f) for f in filter_responses]\n",
    "\n",
    "    m_sigs = []\n",
    "    for r in responses:\n",
    "        max_signal = r[filter_maxima]\n",
    "        m_sigs.append(max_signal)\n",
    "        \n",
    "    covariance = cov(m_sigs, fweights = num_responses, rowvar=False)\n",
    "    \n",
    "    v = np.sqrt(np.diag(covariance))\n",
    "    outer_v = np.outer(v, v)\n",
    "    correlation = covariance / outer_v\n",
    "    correlation[covariance == 0] = 0\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filter_data(filter_info, wavelength):\n",
    "    '''\n",
    "    Converts data from saved filter information (band locations, bandwidths, peak transmissions)\n",
    "    into gaussian filter responses over a wavelength array.\n",
    "    \n",
    "    Inputs\n",
    "        filter_info (L x 3 array): Saved filter information array in the form of (cw, bws, trans)\n",
    "            where cw is Center Wavlength, bws is bandwidths, and trans is peak transmission.\n",
    "    \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            response arrays.\n",
    "            \n",
    "    Outputs\n",
    "        filter_data (L x Q array) - Array of filter responses over the wavelength array.\n",
    "    '''\n",
    "    L,_ = filter_info.shape\n",
    "    Q = len(wavelength)\n",
    "    \n",
    "    filter_data = zeros((L,Q))\n",
    "    \n",
    "    for i in range(L):\n",
    "        cw, bw, t = filter_info[i]\n",
    "        sigma = bw / 2.355 # Convert from FWHM to sigma\n",
    "        filter_data[i] = exp(-(wavelength - cw)**2/(2*sigma**2))*t\n",
    "    \n",
    "    return filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hypercube_MSFA(hypercube, pattern_dims, filter_responses, wavelength, full_res=False):\n",
    "    '''\n",
    "    Generate raw MSFA data from a synthetic hypercube.\n",
    "    \n",
    "    Inputs:\n",
    "        hypercube (N x M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        pattern_dims ((mx, my)) - Tuple of dimensions for macropixel. A 3x3 pixel would be\n",
    "            provided as (3,3) whereas a 3x2 pixel is provided as (3,2), etc.\n",
    "        \n",
    "        filter_responses (J x Q) - Normalized (max of 1) spectral response curves, or QE curves, for each \n",
    "            filter in the MSFA. A total of J different filter responses of the macropixel\n",
    "            should be provided in reading order. J will equal the number of sub-pixels in the macro-pixel.\n",
    "            e.g., px*py = J. Even if there is a duplicate filter, provide the same spectral response curve.\n",
    "            \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            dimension of the hypercube. Filter spectral responses must also be provided on this axis.\n",
    "            \n",
    "        full_res (optional Boolean) - Set to true to generate a reference image with no spatial sampling\n",
    "            effects from the MSFA pattern pixellation. Use to generate \"perfect\" spatial image.\n",
    "    \n",
    "    Outputs:\n",
    "        raw_MSFA (N x M x J) - Series of 2D images showing the collected signal for\n",
    "            a given channel.\n",
    "    '''\n",
    "    mx,my = pattern_dims\n",
    "    N,M,Q = hypercube.shape\n",
    "    J = filter_responses.shape[0]\n",
    "    \n",
    "    if not mx*my == J:\n",
    "        print('The filter response array does not have the correct number of members')\n",
    "        return\n",
    "    \n",
    "    raw_MSFA = zeros((N,M,J))\n",
    "    n = 0\n",
    "    for i in range(mx):\n",
    "        for j in range(my):\n",
    "            \n",
    "            MSFA = zeros((N,M))\n",
    "            filter_response = filter_responses[n]\n",
    "            \n",
    "            \n",
    "            if full_res:\n",
    "                MSFA = sum(hypercube*filter_response,axis=2)\n",
    "            else:\n",
    "                MSFA[j::my,i::mx] = sum(hypercube[j::my,i::mx,:]*filter_response,axis=2)\n",
    "            \n",
    "            raw_MSFA[:,:,n] = MSFA\n",
    "            \n",
    "            n+=1\n",
    "\n",
    "    return raw_MSFA, wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_H(mx,my):\n",
    "    '''\n",
    "    Caclulates the bilinear interpolation filter for a given mosaic.\n",
    "    \n",
    "    Inputs:\n",
    "        mx -  Horizontal array dimension of MSFA macro-pixel.\n",
    "        \n",
    "        my - Vertical array dimension of MSFA macro-pixel.\n",
    "        \n",
    "    Outputs:\n",
    "        H (mx*2-1 x my*2-1) - Weighted, normalized bilinear interpolation filter.\n",
    "    '''\n",
    "\n",
    "    # Initialize empty array\n",
    "    H = zeros((int(my)*2-1,int(mx)*2-1))\n",
    "    \n",
    "    # Define un-normalized filter\n",
    "    for i in range(my+1):\n",
    "        H[i] = r_[arange(1,mx+1),arange(1,mx)[::-1]]*(i+1)\n",
    "\n",
    "    for i in range(my):\n",
    "        H[my*2-2-i] = r_[arange(1,mx+1),arange(1,mx)[::-1]]*(i+1)\n",
    "        \n",
    "    # Normalize\n",
    "    H /= H.max()\n",
    "        \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WB(I,H):\n",
    "    '''\n",
    "    Weighted bilinear interpolation.\n",
    "    \n",
    "    Inputs: \n",
    "        I (N x M array) - Individual channel image from MSFA\n",
    "        \n",
    "        H (2D array) - Weighted, normalized bilinear interpolation filter. Calculated from \n",
    "            mosaic dimensions\n",
    "        \n",
    "    Outputs:\n",
    "        I_wb - Interpolated channel image.\n",
    "        \n",
    "    '''\n",
    "    I_wb = convolve2d(I,H,mode='same')\n",
    "    return I_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_MSFA(N,M,mx,my,L):\n",
    "    '''\n",
    "    Function to create binary mask corresponding to \"observed\" pixels\n",
    "    in a MSFA channel.\n",
    "    \n",
    "    Inputs: \n",
    "        N,M - MSFA image data dimensions\n",
    "        \n",
    "        mx -  Horizontal array dimension of MSFA macro-pixel.\n",
    "        \n",
    "        my - Vertical array dimension of MSFA macro-pixel.\n",
    "        \n",
    "        L - Filter number (reading order)\n",
    "    \n",
    "    Outputs:\n",
    "        mask (N,M) - Binary mask for observed pixels of a given channel.\n",
    "    '''\n",
    "    # This is not very elegant...\n",
    "    output = zeros((N,M))\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(mx):\n",
    "        for j in range(my):\n",
    "            if n == L:\n",
    "                output[j::my,i::mx] = 1.\n",
    "                return output\n",
    "            else:\n",
    "                n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative spectral differences\n",
    "def ISB(I, pattern_dims, corr, iteration=0,verbose=False):\n",
    "    '''\n",
    "    Iterative spectral differences algorithm for demosaicking.\n",
    "    \n",
    "    Inputs:\n",
    "        I (N x M x J array) - MSFA raw data array with J different channels. \n",
    "        \n",
    "        pattern_dims ((mx, my)) - Tuple of dimensions for macropixel. A 3x3 pixel would be\n",
    "                provided as (3,3) whereas a 3x2 pixel is provided as (3,2), etc.\n",
    "        \n",
    "        corr (J x J array) - Correlation matrix describing spectral correlation\n",
    "            between each filter. Used to determine maximum number of iterations\n",
    "        \n",
    "        iteration (int, default=0) - Iteration number, tracked outside of function.\n",
    "        \n",
    "        verbose (optional Boolean) - Set to true for status updates. \n",
    "        \n",
    "    Outputs:\n",
    "        demosaicked (N x M x L array) - Demosaicked MSFA data\n",
    "    \n",
    "    '''\n",
    "    if verbose and not iteration % 10:\n",
    "        print(\"Iteration %d\" % iteration)\n",
    "    \n",
    "    N,M,channels = I.shape\n",
    "    mx,my = pattern_dims\n",
    "    \n",
    "    Nab = exp(corr*3.) # Compute iterations per channel pair\n",
    "    \n",
    "    demosaicked = zeros_like(I)\n",
    "    \n",
    "    H = compute_H(mx,my)\n",
    "    \n",
    "    # Reference - ch1\n",
    "    for ch1 in range(channels):\n",
    "        B1 = binary_mask_MSFA(N,M,mx,my,ch1)\n",
    "        \n",
    "        # Set output data to observed \n",
    "        demosaicked[:,:,ch1][B1==1.] = I[:,:,ch1][B1==1.]\n",
    "        # Target - ch2\n",
    "        for ch2 in range(channels):\n",
    "            if ch1==ch2 or Nab[ch1,ch2]<=iteration:\n",
    "                continue\n",
    "            else:\n",
    "                B2 = binary_mask_MSFA(N,M,mx,my,ch2)\n",
    "                \n",
    "                # Demosaicked channel A\n",
    "                if iteration==0:\n",
    "                    Ca = WB(I[:,:,ch1],H)\n",
    "                else:\n",
    "                    Ca = I[:,:,ch1]\n",
    "                # Apply binary mask for target B\n",
    "                # Subtract from observed to get difference\n",
    "                # Apply bilinear interpolation\n",
    "                Kab = WB(Ca*B2 - I[:,:,ch2]*B2,H)\n",
    "                \n",
    "                # \n",
    "                demosaicked[:,:,ch2][B1==1.] = (Ca - Kab)[B1==1.]\n",
    "\n",
    "    return demosaicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColourSystem:\n",
    "    \"\"\"A class representing a colour system.\n",
    "    \n",
    "    Assume pure white, illuminant E\n",
    "\n",
    "    A colour system defined by the CIE x, y and z=1-x-y coordinates of\n",
    "    its three primary illuminants and its \"white point\".\n",
    "\n",
    "    reference: http://www.brucelindbloom.com/index.html?Eqn_RGB_XYZ_Matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    # The CIE colour matching function for 380 - 780 nm in 5 nm intervals\n",
    "    cmf = np.loadtxt('cie-cmf.txt', usecols=(1,2,3))\n",
    "    wv = arange(380,785,5)\n",
    "                         \n",
    "    def __init__(self, wavelength):\n",
    "        \"\"\"Initialise the ColourSystem object.\n",
    "\n",
    "        Pass vectors (ie NumPy arrays of shape (3,)) for each of the\n",
    "        red, green, blue  chromaticities and the white illuminant\n",
    "        defining the colour system.\n",
    "        \n",
    "        If wavelength is provided, then the CMF function will be re-scaled\n",
    "        to be on the same sampling as the provided array.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Chromaticities\n",
    "        # The chromaticity matrix (RGB -> XYZ) and its inverse (XYZ -> RGB)\n",
    "        # Illuminant 'E'\n",
    "        self.M = array([[0.4887180,0.3106803,0.2006017],[0.1762044,0.8129847,0.0108109],[0.0000000,  0.0102048, 0.9897952]])\n",
    "        self.MI = np.linalg.inv(self.M)\n",
    "\n",
    "        self.cmf = array([interp(wavelength, self.wv, self.cmf[:,0]),\n",
    "                          interp(wavelength, self.wv, self.cmf[:,1]),\n",
    "                          interp(wavelength, self.wv, self.cmf[:,2])]).T\n",
    "        \n",
    "        self.wv = wavelength        \n",
    "        self.N = np.sum(self.cmf[:,1] * ones((len(self.wv),)))\n",
    "\n",
    "    def xyz_to_rgb(self, xyz):\n",
    "        \"\"\"\n",
    "        Transform from xyz to rgb representation of colour.\n",
    "        \"\"\"\n",
    "        rgb = self.MI.dot(xyz)\n",
    "        \n",
    "        # We're not in the RGB gamut: approximate by desaturating\n",
    "        rgb[rgb<0] = 0\n",
    "        rgb[rgb>1] = 1\n",
    "\n",
    "        return rgb\n",
    "\n",
    "    def spec_to_xyz(self, spec):\n",
    "        \"\"\"\n",
    "        Convert a spectrum to an xyz point.\n",
    "        \"\"\"\n",
    "        XYZ = np.sum(spec[:, np.newaxis] * self.cmf, axis=0)\n",
    "        return XYZ / self.N\n",
    "\n",
    "    def spec_to_rgb(self, spec):\n",
    "        \"\"\"Convert a spectrum to an rgb value.\"\"\"\n",
    "        xyz = self.spec_to_xyz(spec)\n",
    "        return self.xyz_to_rgb(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSFA_to_RGB(MSFA, filters, wavelength, verbose=False):\n",
    "    '''\n",
    "    Convert demosaicked MSFA data to RGB spectra using filter responses to\n",
    "    represent complete spectra.\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        MSFA (N x M x J) - MSFA demosaiced data array with J channels / filters. \n",
    "        \n",
    "        filters (J x Q) - Normalized (max of 1) spectral response curves, or QE curves, for each \n",
    "            filter in the MSFA. A total of J different filter responses of the macropixel\n",
    "            should be provided in reading order. J will equal the number of sub-pixels in the macro-pixel.\n",
    "            e.g., px*py = J. Even if there is a duplicate filter, provide the same spectral response curve.\n",
    "        \n",
    "        wavelength (Q x 1) - Array describing the wavelength value corresponding to the spectral\n",
    "            dimension of the hypercube. Filter spectral responses must also be provided on this axis.\n",
    "        \n",
    "        cs - ColorSystem object defining RGB colorspace\n",
    "        \n",
    "        verbose (optional) - Set to true for status updates.\n",
    "    \n",
    "    Outputs: \n",
    "        MSFA_RGB (N x M x 3 array) - RGB-equivalent image generated from MSFA data\n",
    "    \n",
    "    '''\n",
    "    px,py,channels = MSFA.shape\n",
    "    \n",
    "    print('channel shape',MSFA.shape)\n",
    "    print('filter shape',filters.shape)\n",
    "    \n",
    "    cs = ColourSystem(wavelength)\n",
    "    \n",
    "    MSFA_RGB = zeros((px,py,3))\n",
    "    \n",
    "    # Can we do this with an array operation to speed up the \n",
    "    # processing?\n",
    "    \n",
    "    for j in range(py):\n",
    "        if verbose and not j % 100:\n",
    "            print(\"Converting row %d\" %j)\n",
    "        for i in range(px):\n",
    "            spectra = zeros_like(filters[0])\n",
    "            spectra = spectra.astype(np.float64)\n",
    "\n",
    "            for c in range(0,int(channels-1)):\n",
    "                #print('c',c)\n",
    "                spectra += MSFA[j,i,c]*filters[c]\n",
    "                \n",
    "            MSFA_RGB[j,i,:] = cs.spec_to_rgb(spectra)\n",
    "            \n",
    "    return MSFA_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypercube_to_RGB(hypercube,wavelength,verbose=False):\n",
    "    '''\n",
    "    Convert hyperspectral data to RGB\n",
    "    \n",
    "    Inputs:\n",
    "        hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            response arrays.    \n",
    "            \n",
    "        cs - ColorSystem object defining RGB colorspace\n",
    "        \n",
    "    Outputs:\n",
    "        hypercube_RGB (N x M x 3) - RGB-equivalent image generated from hyperspectral data.\n",
    "    \n",
    "    '''\n",
    "    px,py,wv = hypercube.shape\n",
    "    \n",
    "    hypercube_RGB = zeros((px,py,3))\n",
    "    \n",
    "    cs = ColourSystem(wavelength)\n",
    "    \n",
    "    # Can we do this with an array operation to speed up the \n",
    "    # processing?\n",
    "    \n",
    "    for j in range(py):\n",
    "        if verbose and not j % 100:\n",
    "            print(\"Converting row %d\" %j)\n",
    "        for i in range(px):\n",
    "            hypercube_RGB[j,i,:] = cs.spec_to_rgb(hypercube[j,i])\n",
    "            \n",
    "    return hypercube_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS_pixel_difference(im,ref):\n",
    "    '''\n",
    "    Total RMS error between an image (im) and reference (ref). Used as a merit function.\n",
    "    \n",
    "    Inputs:\n",
    "        im (N x M array) - Image to test quality.\n",
    "    \n",
    "        ref (M x M array) - Reference to compare test image to.\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "        rms (float): RMS pixel difference between input image and a reference.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # How to account for scaling between channels?\n",
    "    d = im / im.max(axis=(0,1))\n",
    "    rms = sqrt( mean((d-ref)**2) )\n",
    "        \n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft\n",
    "import numpy as np\n",
    "\n",
    "def DFT_difference(im,ref):\n",
    "    '''\n",
    "    Merit function option to compute difference between two images\n",
    "    in fourier space using discrete fourier transform.\n",
    "    \n",
    "        Inputs:\n",
    "        im (N x M array) - Image to test quality.\n",
    "    \n",
    "        ref (M x M array) - Reference to compare test image to.\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "        dft_diff (float): \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # TO DO: Write this function\n",
    "    # How to account for scaling between channels?\n",
    "    d = im / im.max(axis=(0,1))\n",
    "    xf = fft(im)\n",
    "    yf = fft(ref)\n",
    "    \n",
    "    dft_diff = sqrt(mean((np.real(yf-xf))**2))\n",
    "    \n",
    "    return dft_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_rank( hypercube,opti_bw, opti_wavelength, wavelength,transmissivity, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        1) hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        2) bandwidth\n",
    "        3) wavelength\n",
    "        4) transmissivity \n",
    "  \n",
    "    \n",
    "        ranking depends on three factor: \n",
    "        1) Total area of each filter \n",
    "        2) The total intensity recieved by this chanel \n",
    "        \n",
    "    Output:\n",
    "         a matrix with wavelength, bandwidth, intensity recieved\n",
    "         \n",
    "    Could be improve:\n",
    "       ranking way\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # preparation\n",
    "    filter_number = len(opti_wavelength)\n",
    "    N,M,Q = hypercube.shape\n",
    "    hypercube = hypercube.reshape(N*M,Q)\n",
    "    print('hypercube shape',hypercube.shape)\n",
    "    Intensity_recieved = zeros((N*M,Q))\n",
    "    #number_of_filter \n",
    "    \n",
    "    L = len(opti_wavelength)\n",
    "    print(L)\n",
    "    filters = []\n",
    "    \n",
    "    #matrxi for wavelength and bw, intensity, ranked by intensity\n",
    "    matrix = zeros((L,3))\n",
    "    matrix[:,0] = np.array(opti_wavelength)\n",
    "    matrix[:,1] = np.array(opti_bw)\n",
    "\n",
    "    # Define filter responses, add them together, not a elegant way, should improve it later\n",
    "    filters =[ transmissivity[i] * exp(-(wavelength - opti_wavelength[i])**2 / (2*(opti_bw[i]/2.355)**2)) for i in range(len(opti_wavelength))]\n",
    "    \n",
    "    print('number of filter type',len(filters))    \n",
    "    \n",
    "    \n",
    "    #intensity factor\n",
    "    for m in range(0,L):\n",
    "        for n in range(0,N*M):\n",
    "            Intensity_recieved[n,m]=np.dot(hypercube[n],filters[m])\n",
    "        sum_over_spectra = Intensity_recieved.sum(1)\n",
    "        \n",
    "        sum_over_pixel = sum_over_spectra.sum()\n",
    "        matrix[m,2] = sum_over_pixel\n",
    "    \n",
    "    #rank it by intensity, from low to high\n",
    "    matrix_ranked = matrix[np.argsort(matrix[:,2])]\n",
    "\n",
    "    return matrix_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_duplication(pattern_dims,hypercube,opti_bw, opti_wavelength,wavelength,transmissivity, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        1) hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        2) bandwidth\n",
    "        3) wavelength\n",
    "        4) number of block (mxXny)\n",
    "        \n",
    "    Output:\n",
    "         f_filter that matched with number of block in the pattern (blocks, wavlength region)\n",
    "         \n",
    "    Could be improve:\n",
    "       ranking way\n",
    "    '''\n",
    "    ranked_table = intensity_rank(hypercube,opti_bw, opti_wavelength,wavelength,transmissivity,verbose=False)\n",
    "    filter_number,_ = ranked_table.shape\n",
    "    print('filter_number',filter_number)\n",
    "\n",
    "    X,Y = pattern_dims\n",
    "    number_of_block = X*Y\n",
    "    print('number_of_block',number_of_block)\n",
    "    \n",
    "    W = wavelength.shape[0]\n",
    "    f = zeros((number_of_block,int(W)))\n",
    "    filter_labels = zeros((number_of_block))\n",
    "    \n",
    "    if filter_number > number_of_block:\n",
    "        # use top intensity \n",
    "        for i in range(0,(number_of_block)):\n",
    "            print(i)\n",
    "            # pick from high intensity\n",
    "            number = filter_number-1-i\n",
    "            print(number)\n",
    "            opti_wavelength = ranked_table[number,0]\n",
    "            opti_bw = ranked_table[number,1]\n",
    "            print(opti_wavelength)\n",
    "            f[i] = exp(-(wavelength - opti_wavelength)**2 / (2*(opti_bw/2.355)**2))\n",
    "            filter_labels[i] = opti_wavelength\n",
    "\n",
    "    else:\n",
    "        # need duplicate\n",
    "        for i in range(0,(number_of_block)):\n",
    "            # pick from high intensity\n",
    "            number = filter_number-i-1\n",
    "            if number >= 0:\n",
    "                number = number\n",
    "                opti_wavelength = ranked_table[number,0]\n",
    "                opti_bw = ranked_table[number,1]\n",
    "                f[i] = exp(-(wavelength - opti_wavelength)**2 / (2*(opti_bw/2.355)**2))\n",
    "                filter_labels[i] = opti_wavelength\n",
    "                print('No',number)\n",
    "                print('opti_wave',opti_wavelength)\n",
    "            else:\n",
    "                number = filter_number - abs(number)\n",
    "                opti_wavelength = ranked_table[number,0]\n",
    "                opti_bw = ranked_table[number,1]\n",
    "                f[i] = exp(-(wavelength - opti_wavelength)**2 / (2*(opti_bw/2.355)**2))\n",
    "                filter_labels[i] = opti_wavelength\n",
    "                print('No',number)\n",
    "                print('opti_wave',opti_wavelength)\n",
    "            #print('filter',number)\n",
    "    #print(\"filters respond shape:\", f.shape)\n",
    "\n",
    "        \n",
    "    return f, filter_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_area_matrix(hypercube, opti_bw, opti_wavelength, wavelength, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        1) hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        2) filter_responses (Q X P) - P is the number of filters.\n",
    "        3) wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            dimension of the hypercube.\n",
    "    \n",
    "    Output:\n",
    "        correlation_relation depends on three factor: \n",
    "        1) Total area of each filter \n",
    "        2) Cross area of arbitary two filter\n",
    "        3) The total intensity recieved by this chanel \n",
    "        \n",
    "    Could be improve:\n",
    "        1) the weight bwtween this three factors\n",
    "        2) the normalize method while dealing with the 'total intensity' given by the hypercube\n",
    "        \n",
    "    '''\n",
    "    # preparation\n",
    "    filter_number = len(opti_wavelength)\n",
    "    N,M,Q = hypercube.shape\n",
    "    hypercube = hypercube.reshape(N*M,Q)\n",
    "    print('hypercube shape',hypercube.shape)\n",
    "    Intensity_recieved = zeros((N*M,Q))\n",
    "    #number_of_filter \n",
    "    L = len(opti_wavelength)\n",
    "    filters = []\n",
    "    \n",
    "    #matrxi for wavelength and bw, intensity, ranked by intensity\n",
    "    matrix = zeros((L,3))\n",
    "    matrix[:,0] = opti_wavelength\n",
    "    matrix[:,1] = opti_bw\n",
    "\n",
    "    # Define filter responses, add them together, not a elegant way, should improve it later\n",
    "    filters = [exp(-(wavelength - opti_wavelength[i])**2 / (2*(opti_bw[i]/2.355)**2)) for i in range(len(opti_wavelength))]\n",
    "    filter_responses = np.array(filters)\n",
    "    filter_responses = filter_responses.T\n",
    "   \n",
    "    print('filter_response shape',filter_responses.shape)\n",
    "\n",
    "    K,P = filter_responses.shape\n",
    "    cross_area = zeros((P,P))\n",
    "    hyper = zeros((K,P))\n",
    "    \n",
    "    # Normalize spectral data per pixel, use mean of the intensity to normalized it\n",
    "    hyper_combine_filter = []\n",
    "    hsi_norm = hypercube.mean(axis=0)\n",
    "    hsi_norm[hsi_norm==0] = 1.\n",
    "    \n",
    "    print(hsi_norm.shape)\n",
    "    \n",
    "    #introduce this factor to filter\n",
    "    for n in range(K):\n",
    "        for m in range(P):\n",
    "            hyper[n,m]=np.vdot(hsi_norm[n],filter_responses[n,m])\n",
    "    \n",
    "    # Normalize spectral data per pixel, use mean of the intensity to normalized it\n",
    "    hyper_combine_filter = []\n",
    "    hsi_norm = hypercube.mean(axis=0)\n",
    "    hsi_norm[hsi_norm==0] = 1.\n",
    "    \n",
    "    \n",
    "    #introduce this factor to filter\n",
    "    for n in range(K):\n",
    "        for m in range(P):\n",
    "            hyper[n,m]=np.vdot(hsi_norm[n],filter_responses[n,m])\n",
    "        \n",
    "    print(hyper.shape)\n",
    "    # calculate the cross area for each filters, \n",
    "    # the diagonal provides the information of the height of this filter,somehow provide the information of total area\n",
    "\n",
    "    \n",
    "    #  Give weight bwtween these factors\n",
    "    # here just multiply them together\n",
    "    filter_responses = hyper\n",
    "    \n",
    "    for i in range(P):\n",
    "        for j in range(P):\n",
    "            if i != j:\n",
    "                cross_area[i,j]= np.vdot(filter_responses[:,i],filter_responses[:,j])\n",
    "            else :\n",
    "                cross_area[i,i] = 0\n",
    "    #print(cross_area)\n",
    "    \n",
    "            \n",
    "    \n",
    "    return abs(cross_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_optimization_MSFA(hypercube,wavelength,pattern_dims, opti_bw, opti_wavelength,transmissivity, demosaicking='ISB',op_type='exhaustive', merit_function='RMS',verbose=True,drop_dignal=False,speed_up = True):\n",
    "        '''\n",
    "        Full spatial optimization pipeline to determine the optimal filter\n",
    "        pattern for a multispectral filter array given a synthetic hypercube\n",
    "        target, and filter responses.\n",
    "        \n",
    "        Inputs:\n",
    "            hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "            \n",
    "            wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "                response arrays.\n",
    "            \n",
    "            pattern_dims ((mx, my)) - Tuple of dimensions for macropixel. A 3x3 pixel would be\n",
    "                provided as (3,3) whereas a 3x2 pixel is provided as (3,2), etc.\n",
    "\n",
    "            filters (J x Q) - Normalized (max of 1) spectral response curves, or QE curves, for each \n",
    "                filter in the MSFA. A total of J different filter responses of the macropixel\n",
    "                should be provided in reading order. J will equal the number of sub-pixels in the macro-pixel.\n",
    "                e.g., px*py = J. Even if there is a duplicate filter, provide the same spectral response curve.\n",
    "\n",
    "            filter_labels (optional J x 1 List): List of labels for each filter\n",
    "            \n",
    "            demosaicking (optional): \n",
    "                'ISB' - Iterative spectral differences (default) \n",
    "                'WB' - Weighted bi-linear interpolation\n",
    "        \n",
    "            op_type (optional): Type of optimization.\n",
    "                'exhaustive' - test every possible spatial arrangement\n",
    "        \n",
    "            merit_function (optional):\n",
    "                'RMS' - Computes RMS pixel differences between (default)\n",
    "                'RMS-RGB' - Computes RMS pixel differences between\n",
    "                'DFT'\n",
    "                'DFT-RGB'\n",
    "            \n",
    "            verbose (optional): Set to true for status updates\n",
    "            \n",
    "        Outputs:\n",
    "            pattern\n",
    "        '''\n",
    "        \n",
    "        filter_number = len(opti_wavelength)\n",
    "        print('wavelenght',wavelength.shape)\n",
    "        \n",
    "\n",
    "        \n",
    "        # generate duplication\n",
    "        filters,filter_labels = generate_duplication(pattern_dims,hypercube,opti_bw, opti_wavelength,wavelength,transmissivity, verbose=False)\n",
    "        print('filter label ranked by intensity',filter_labels)\n",
    "       \n",
    "        X,Y = pattern_dims\n",
    "        number_of_block = X*Y\n",
    "    \n",
    "\n",
    "        if drop_dignal == True:  \n",
    "            print('fixed diagnol element by largest cross area')\n",
    "            cross_area = cross_area_matrix(hypercube,opti_bw, opti_wavelength, wavelength, verbose=False)\n",
    "            print('cross area matrix. shape',cross_area.shape)\n",
    "            #find the two filters with biggest cross area, then put them in diagonal\n",
    "            max_cross_area = np.max(cross_area)\n",
    "            location = np.where(cross_area ==np.max(max_cross_area))\n",
    "            # find the position of these two filter \n",
    "            lo = zeros((4))\n",
    "            s = 0\n",
    "            for n in location:\n",
    "                for m in n:\n",
    "                    lo[s] = m\n",
    "                    s += 1       \n",
    "            #print(lo)\n",
    "            diag1 = int(lo[0])\n",
    "            diag2 = int(lo[1])\n",
    "            print('diagnol two are filter No.', diag1,'and', diag2, \"with centre wavelength\",opti_wavelength[diag1],'and',opti_wavelength[diag2])\n",
    "\n",
    "            # drop 2 diagnoal filter \n",
    "            loc1 = np.where(filter_labels ==opti_wavelength[diag1])\n",
    "            loc2 = np.where(filter_labels ==opti_wavelength[diag2])\n",
    "            print('check',opti_wavelength[diag2])\n",
    "            print('check',loc2)\n",
    "            for q in loc1:\n",
    "                for x in q:\n",
    "                    pos1 = int(x)\n",
    "                    print('pos1:',pos1,\"with centre wavelength\",opti_wavelength[diag1])\n",
    "            for y in loc2:\n",
    "                for z in y:\n",
    "                    if int(z) < filter_number:\n",
    "                        pos2 = int(z)\n",
    "                        print('pos2:',pos2,\"with centre wavelength\",opti_wavelength[diag2])\n",
    "\n",
    "            if pos2 > pos1:\n",
    "                filters_s = np.delete(filters,pos1,0)\n",
    "                filters_s = np.delete(filters_s,int(pos2 - 1),0)\n",
    "            else:\n",
    "                filters_s = np.delete(filters,pos1,0)\n",
    "                filters_s = np.delete(filters_s,int(pos2 - 1),0)\n",
    "\n",
    "            f1 = filters[pos1]\n",
    "            f2 = filters[pos2]\n",
    "\n",
    "            print('after delete 2 diagnal filter. shape',filters_s.shape)\n",
    "            N_filters,_ = filters_s.shape\n",
    "            \n",
    "        else:\n",
    "            N_filters,_ = filters.shape\n",
    "            \n",
    "        #corr = generate_correlation_matrix(hypercube,filters,wavelength)\n",
    "        #print('generating correlation matrix, shape:', corr.shape)\n",
    "        # Iterate through every possible permutation of the filter arrangement\n",
    "        \n",
    "        \n",
    "        # Iterate through every possible permutation of the filter arrangement\n",
    "        if op_type == 'exhaustive':\n",
    "            best = inf\n",
    "            pattern = []\n",
    "            best_demosaicked = None\n",
    "            results = []\n",
    "            pattern_labels = []\n",
    "            \n",
    "            # to speed up in order to get rid of symmtry\n",
    "            if pattern_dims == (2,2) and speed_up == True:\n",
    "                fil_set_pool = [(0,1,2,3),(0,3,1,2),(0,3,2,1)]\n",
    "                    \n",
    "               \n",
    "            elif drop_dignal == True:   \n",
    "                    # count the number of available choices\n",
    "                    H=0\n",
    "                    for fil_set in permutations(arange(N_filters), N_filters):\n",
    "                        H +=1\n",
    "                    print('number of choice',H)\n",
    "                    \n",
    "                    \n",
    "                    i = 0\n",
    "                    for fil_set in permutations(arange(N_filters), N_filters):\n",
    "                        print('set',fil_set)\n",
    "                        fil_set = np.insert(fil_set,0,diag1)\n",
    "                        fil_set = np.insert(fil_set,H+1,diag2)\n",
    "                        print(fil_set)\n",
    "                        if i == 0:\n",
    "                            fil_set_pool = fil_set\n",
    "                        else:\n",
    "                            fil_set_pool = [fil_set_pool,fil_set]\n",
    "                        i = i+1    \n",
    "            \n",
    "            else: \n",
    "                fil_set_pool = permutations(arange(N_filters), N_filters)\n",
    "                \n",
    "            for fil_set in fil_set_pool:\n",
    "                \n",
    "                f = array([filters[i] for i in fil_set])\n",
    "                # Generate raw MSFA data\n",
    "                raw, _ = sample_hypercube_MSFA(hypercube,pattern_dims,f,wavelength)\n",
    "                \n",
    "                # Generate perfect spatial reference\n",
    "                ref,_ = sample_hypercube_MSFA(hypercube,pattern_dims,f,wavelength,full_res=True)\n",
    "                \n",
    "                # Demosaic the raw MSFA data using iterative spectral differences\n",
    "                if demosaicking == \"WB\":\n",
    "                    if verbose:\n",
    "                        print(\"Using weighted bilinear interpolation for demosaicking.\")\n",
    "                    H = compute_H(*pattern_dims)\n",
    "                    demosaicked = zeros_like(raw)\n",
    "                    for c in range(len(f)):\n",
    "                        demosaicked[:,:,c] = WB(raw[:,:,c],H)\n",
    "                \n",
    "                else:\n",
    "                    #ISB need corr\n",
    "                    corr = generate_correlation_matrix(hypercube,filters,wavelength)\n",
    "                    if verbose:\n",
    "                        print(\"Using iterative spectral differences with %i iterations\" %int(exp(corr.max()*3.)))\n",
    "                    for iteration in range(int(exp(corr.max()*3.))):\n",
    "                        demosaicked = ISB(raw,pattern_dims, corr, iteration=iteration,verbose=verbose)\n",
    "                \n",
    "                if merit_function == 'RMS-RGB':\n",
    "                    demosaicked_RGB = MSFA_to_RGB(demosaicked, f, wavelength)\n",
    "                    ref_RGB = hypercube_to_RGB(hypercube,wavelength)\n",
    "                    m = RMS_pixel_difference(demosaicked_RGB, ref_RGB)\n",
    "                    print('RMS-RGB')\n",
    "                \n",
    "                elif merit_function == 'DFT':\n",
    "                    m = DFT_difference(demosaicked, ref)\n",
    "                    demosaicked_RGB = demosaicked\n",
    "                    print('DFT')\n",
    "                    \n",
    "                elif merit_function == 'DFT-RGB':\n",
    "                    demosaicked_RGB = MSFA_to_RGB(demosaicked, f, wavelength)\n",
    "                    ref_RGB = hypercube_to_RGB(hypercube,wavelength)\n",
    "                    m = DFT_difference(demosaicked_RGB, ref_RGB)\n",
    "                    print('DFT-RGB')\n",
    "                    \n",
    "                else: # Default\n",
    "                    m = RMS_pixel_difference(demosaicked, ref)\n",
    "                    demosaicked_RGB = demosaicked\n",
    "                    print('RMS')\n",
    "                    \n",
    "                results.append(m)\n",
    "                \n",
    "                if m < best:\n",
    "                    best = m\n",
    "                    pattern = fil_set\n",
    "                    best_demosaicked = demosaicked\n",
    "                    pattern_labels = [filter_labels[i] for i in fil_set]\n",
    "                    \n",
    "                if verbose:\n",
    "                    print(\"Using pattern (reading order) of \", [filter_labels[i] for i in fil_set], \"gives merit function result of\", results[-1])\n",
    "        else:\n",
    "            print(\"Optimizations other than exhaustive are not yet supported.\")\n",
    "            \n",
    "            return False\n",
    "\n",
    "        \n",
    "        return pattern, pattern_labels, demosaicked,demosaicked_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysptools import abundance_maps\n",
    "\n",
    "def compute_unmixing_accuracy(hypercube, abundance_map, endmembers, wavelength, center_wavelengths, bandwidths, return_predicted=False):\n",
    "    '''\n",
    "    Function to compute unmixing accuracy using NNLS spectral unmixing given a set of spectral band \n",
    "    center wavelengths and bandwidths. Assuming gaussian filter responses with a bandwidth defined\n",
    "    as the FWHM.\n",
    "    \n",
    "    Inputs:\n",
    "        hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        abundance_map (N x M x P)- 3D ground-truth abundance map of target. Each channel in L corresponds to the\n",
    "             abundance (between 0 and 1) of the spectral signature in the spectra array. \n",
    "        \n",
    "        endmembers (P x Q array) - Array of endmember signals to unmix.\n",
    "        \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            response arrays.\n",
    "        \n",
    "        center_wavelengths (1 x L array) - Array or list of center wavelengths for Gaussian filter responses\n",
    "            to use for unmixing.\n",
    "        \n",
    "        bandwidths (1 x L array) - Array or list of bandwidths for Gaussian filter responses\n",
    "            to use for unmixing.\n",
    "        \n",
    "    Outputs:\n",
    "        accuracy (float) - RMS error of the unmixed abundance compared to the gruond truth\n",
    "        \n",
    "        predicted (optional N x M x P array) - Predicted abundance map of hypercube\n",
    "    '''\n",
    "    # Extract relevant dimensions\n",
    "    N,M,Q = hypercube.shape\n",
    "    \n",
    "    # Define filter responses\n",
    "    filters = [exp(-(wavelength - center_wavelengths[i])**2 / (2*(bandwidths[i]/2.355)**2)) for i in range(len(center_wavelengths))]\n",
    "    \n",
    "    P = len(endmembers)\n",
    "    L = len(filters)\n",
    "    \n",
    "    # Pre-allocate arrays\n",
    "    data_sig = zeros((N*M,L))\n",
    "    endmember_sig = zeros((P,L))\n",
    "    \n",
    "    # Iterate through each filter\n",
    "    for i,f in enumerate(filters):\n",
    "        # Compute the signal from each filter received from the data\n",
    "        # and that received from an endmember.\n",
    "        data_sig[:,i] = sum(hypercube.reshape((N*M,Q))*f,axis=1) # (N*M) x L\n",
    "        \n",
    "        for j, e in enumerate(endmembers):\n",
    "            endmember_sig[j,i] = sum(endmembers[j]*f) # P x Q\n",
    "            \n",
    "    # Reshape the data array into 1d array\n",
    "    predicted = abundance_maps.amaps.NNLS(data_sig, endmember_sig) # (N*M x P)\n",
    "\n",
    "    # Take RMS difference between true abundance map and computed.\n",
    "    accuracy = sqrt(mean((abundance_map.reshape((N*M,len(endmember_sig)))-predicted)**2))\n",
    "    \n",
    "    print('acc = ',accuracy)\n",
    "    if not accuracy or isnan(accuracy):\n",
    "        return 100.\n",
    "    \n",
    "    if return_predicted:\n",
    "        return accuracy, predicted.reshape((N,M,P))\n",
    "    else:\n",
    "        return accuracy,predicted.reshape((N,M,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unmixing_accuracy_demosaicked(hypercube, abundance_map, endmembers, wavelength, center_wavelengths, bandwidths,demosaicked, return_predicted=False):\n",
    "    '''\n",
    "    Function to compute unmixing accuracy using NNLS spectral unmixing given a set of spectral band \n",
    "    center wavelengths and bandwidths. Assuming gaussian filter responses with a bandwidth defined\n",
    "    as the FWHM.\n",
    "    \n",
    "    Inputs:\n",
    "        hypercube (N X M x Q) - 3D synthetic hypercube.\n",
    "        \n",
    "        abundance_map (N x M x P)- 3D ground-truth abundance map of target. Each channel in L corresponds to the\n",
    "             abundance (between 0 and 1) of the spectral signature in the spectra array. \n",
    "        \n",
    "        endmembers (P x Q array) - Array of endmember signals to unmix.\n",
    "        \n",
    "        wavelength (1 x Q array) - Array describing the wavelength value corresponding to the spectral\n",
    "            response arrays.\n",
    "        \n",
    "        center_wavelengths (1 x L array) - Array or list of center wavelengths for Gaussian filter responses\n",
    "            to use for unmixing.\n",
    "        \n",
    "        bandwidths (1 x L array) - Array or list of bandwidths for Gaussian filter responses\n",
    "            to use for unmixing.\n",
    "        \n",
    "    Outputs:\n",
    "        accuracy (float) - RMS error of the unmixed abundance compared to the gruond truth\n",
    "        \n",
    "        predicted (optional N x M x P array) - Predicted abundance map of hypercube\n",
    "    '''\n",
    "    # Extract relevant dimensions\n",
    "    N,M,Q = hypercube.shape\n",
    "    \n",
    "    # Define filter responses\n",
    "    filters = [exp(-(wavelength - center_wavelengths[i])**2 / (2*(bandwidths[i]/2.355)**2)) for i in range(len(center_wavelengths))]\n",
    "    \n",
    "    P = len(endmembers)\n",
    "    L = len(filters)\n",
    "    \n",
    "    # Pre-allocate arrays\n",
    "    data_sig = zeros((N*M,L))\n",
    "    endmember_sig = zeros((P,L))\n",
    "    demosaicked = demosaicked.reshape((N*M,P))\n",
    "    \n",
    "    \n",
    "    # Iterate through each filter\n",
    "    for i,f in enumerate(filters):\n",
    "        # Compute the signal from each filter received from the data\n",
    "        # and that received from an endmember.\n",
    "        data_sig[:,i] = demosaicked[:,i]\n",
    "        \n",
    "        for j, e in enumerate(endmembers):\n",
    "            endmember_sig[j,i] = sum(endmembers[j]*f) # P x Q\n",
    "   \n",
    "    print('pic',len(endmember_sig))\n",
    "    truth = abundance_map.reshape((N*M,len(endmember_sig)))\n",
    "  \n",
    "    # Reshape the data array into 1d array\n",
    "    predicted = abundance_maps.amaps.NNLS(data_sig, endmember_sig) # (N*M x P)\n",
    "\n",
    "    #print(truth.shape)\n",
    "    #print(predicted.shape)\n",
    "    # Take RMS difference between true abundance map and computed.\n",
    "    accuracy = sqrt(mean((truth-predicted)**2))\n",
    "    \n",
    "    if not accuracy or isnan(accuracy):\n",
    "        return 100.\n",
    "    \n",
    "    if return_predicted:\n",
    "        return accuracy, predicted.reshape((N,M,P))\n",
    "    else:\n",
    "        return accuracy,predicted.reshape((N,M,P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"samson\"\n",
    "\n",
    "d = loadmat(\"../input/reference-datasets/\" + dataset + \"/\" + dataset + \".mat\")\n",
    "em = loadmat(\"../input/reference-datasets/\" + dataset + \"/endmembers/endmembers.mat\")\n",
    "dinfo = pd.read_csv(\"../input/reference-datasets/\" + dataset + \"/info.csv\",header=None,index_col=None,names=[\"parameter\",'value','unit'])\n",
    "\n",
    "nrow = int(dinfo[dinfo['parameter'] == 'nrow'].value.values[0])\n",
    "ncol = int(dinfo[dinfo['parameter'] == 'ncol'].value.values[0])\n",
    "\n",
    "nbands = int(dinfo[dinfo['parameter'] == 'nbands'].value.values[0])\n",
    "spec_start = dinfo[dinfo['parameter'] == 'spec_start'].value.values[0]\n",
    "spec_end = dinfo[dinfo['parameter'] == 'spec_end'].value.values[0]\n",
    "\n",
    "data = d['Y']\n",
    "data = data / data.max()\n",
    "\n",
    "try:\n",
    "    spec_bands = d['SlectBands'].flatten()\n",
    "except:\n",
    "    spec_bands = arange(0,nbands)\n",
    "\n",
    "# Define wavelength array\n",
    "wavelength = linspace(spec_start,spec_end,nbands)\n",
    "wavelength = wavelength[spec_bands]\n",
    "\n",
    "if len(em['M']) > len(wavelength):\n",
    "    endmembers = em['M'][spec_bands]\n",
    "else:\n",
    "    endmembers = em['M']\n",
    "\n",
    "endmembers = endmembers.reshape(len(wavelength),-1)\n",
    "\n",
    "a_map = em[\"A\"].reshape((endmembers.shape[1],nrow,ncol)).T\n",
    "\n",
    "hypercube = data.copy()\n",
    "spectra = endmembers.T\n",
    "hypercube = hypercube.reshape(len(wavelength), a_map.shape[1], a_map.shape[0]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 156)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_wavelength = [528., 684., 760.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_bw = [20,20,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmissivity = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_dims = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option, create hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, w = create_sythentic_hypercube(a_map,spectra,wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t += rand(95,95,156)*0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypercube = hypercube[20:40,20:40,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavelenght (156,)\n",
      "hypercube shape (400, 156)\n",
      "3\n",
      "number of filter type 3\n",
      "filter_number 3\n",
      "number_of_block 4\n",
      "No 2\n",
      "opti_wave 760.0\n",
      "No 1\n",
      "opti_wave 684.0\n",
      "No 0\n",
      "opti_wave 528.0\n",
      "No 2\n",
      "opti_wave 760.0\n",
      "filter label ranked by intensity [760. 684. 528. 760.]\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 684.0, 528.0, 760.0] gives merit function result of 1.2902787103274806\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 684.0, 760.0, 528.0] gives merit function result of 1.2990328325844938\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 528.0, 684.0, 760.0] gives merit function result of 1.2899988611561293\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 528.0, 760.0, 684.0] gives merit function result of 1.3011982263774953\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 760.0, 684.0, 528.0] gives merit function result of 1.2979325421190124\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 760.0, 528.0, 684.0] gives merit function result of 1.300377443908962\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 760.0, 528.0, 760.0] gives merit function result of 1.2970385109615385\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 760.0, 760.0, 528.0] gives merit function result of 1.317905470824947\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 528.0, 760.0, 760.0] gives merit function result of 1.2978614050113595\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 528.0, 760.0, 760.0] gives merit function result of 1.2978614050113595\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 760.0, 760.0, 528.0] gives merit function result of 1.317905470824947\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [684.0, 760.0, 528.0, 760.0] gives merit function result of 1.2970385109615385\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 760.0, 684.0, 760.0] gives merit function result of 1.292447146557059\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 760.0, 760.0, 684.0] gives merit function result of 1.3180928813078032\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 684.0, 760.0, 760.0] gives merit function result of 1.2935521028874157\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 684.0, 760.0, 760.0] gives merit function result of 1.2935521028874157\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 760.0, 760.0, 684.0] gives merit function result of 1.3180928813078032\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [528.0, 760.0, 684.0, 760.0] gives merit function result of 1.292447146557059\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 760.0, 684.0, 528.0] gives merit function result of 1.2979325421190124\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 760.0, 528.0, 684.0] gives merit function result of 1.300377443908962\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 684.0, 760.0, 528.0] gives merit function result of 1.2990328325844938\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 684.0, 528.0, 760.0] gives merit function result of 1.2902787103274806\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 528.0, 760.0, 684.0] gives merit function result of 1.3011982263774953\n",
      "Using iterative spectral differences with 20 iterations\n",
      "Iteration 0\n",
      "Iteration 10\n",
      "RMS\n",
      "Using pattern (reading order) of  [760.0, 528.0, 684.0, 760.0] gives merit function result of 1.2899988611561293\n"
     ]
    }
   ],
   "source": [
    "best_pattern, best_pattern_labels, demosaicked,demosaicked_RGB = spatial_optimization_MSFA(hypercube,wavelength,pattern_dims,opti_bw,opti_wavelength,transmissivity,demosaicking ='ISB', merit_function='RMS',drop_dignal=False,speed_up = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[760.0, 528.0, 684.0, 760.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pattern_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 1, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to point out, here I just linearly add two image together and average out to give the img for the color with duplication, it should have other better way to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "subplot(2,2,1)\n",
    "plt.imshow(demosaicked[:,:,2],cmap=cm.gray,vmin=0,vmax=demosaicked.max())\n",
    "axis(\"off\")\n",
    "title('demosaicked figure 1')\n",
    "subplot(2,2,2)\n",
    "plt.imshow(demosaicked[:,:,1],cmap=cm.gray,vmin=0,vmax=demosaicked.max())\n",
    "axis(\"off\")\n",
    "title('demosaicked figure 2')\n",
    "subplot(2,2,3)\n",
    "#plt.imshow(demosaicked[:,:,2],cmap=cm.gray,vmin=0,vmax=demosaicked.max())\n",
    "#axis(\"off\")\n",
    "subplot(2,2,3)\n",
    "plt.imshow((demosaicked[:,:,0]+demosaicked[:,:,3])/2,cmap=cm.gray,vmin=0,vmax=demosaicked.max())\n",
    "axis(\"off\")\n",
    "title('demosaicked figure 3')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "plt.imshow(demosaicked_RGB,vmin=0,vmax=demosaicked_RGB.max())\n",
    "axis(\"off\")\n",
    "title('demosaicked_RGB')\n",
    "\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start unmixing to find the abundance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demosaicked_af = zeros((95,95,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demosaicked_af.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three imag put back to the unmixing acc need to be in the sequence of opti-wavelenght given before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demosaicked_af[:,:,0] = demosaicked[:,:,1]\n",
    "demosaicked_af[:,:,1] = demosaicked[:,:,2]\n",
    "demosaicked_af[:,:,2]= (demosaicked[:,:,0]+demosaicked[:,:,3])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,predicted_map = compute_unmixing_accuracy_demosaicked(hypercube, a_map, spectra, wavelength, opti_wavelength, opti_bw,demosaicked_af, return_predicted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "subplot(2,2,1)\n",
    "title('Prediected abundance map 1')\n",
    "plt.imshow(predicted_map[:,:,0],cmap=cm.gray,vmin=0,vmax=predicted_map.max())\n",
    "axis(\"off\")\n",
    "subplot(2,2,2)\n",
    "title('Prediected abundance map 2')\n",
    "plt.imshow(predicted_map[:,:,1],cmap=cm.gray,vmin=0,vmax=predicted_map.max())\n",
    "axis(\"off\")\n",
    "subplot(2,2,3)\n",
    "plt.imshow(predicted_map[:,:,2],cmap=cm.gray,vmin=0,vmax=predicted_map.max())\n",
    "axis(\"off\")\n",
    "title('Prediected abundance map 3')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1,initial_map = compute_unmixing_accuracy(hypercube, a_map, spectra, wavelength, opti_wavelength, opti_bw, return_predicted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "subplot(2,2,1)\n",
    "title('unmixing abundance map 1')\n",
    "plt.imshow(initial_map[:,:,0],cmap=cm.gray,vmin=0,vmax=initial_map.max())\n",
    "axis(\"off\")\n",
    "subplot(2,2,2)\n",
    "title('unmixing abundance map 2')\n",
    "plt.imshow(initial_map[:,:,1],cmap=cm.gray,vmin=0,vmax=initial_map.max())\n",
    "axis(\"off\")\n",
    "subplot(2,2,3)\n",
    "plt.imshow(initial_map[:,:,2],cmap=cm.gray,vmin=0,vmax=initial_map.max())\n",
    "axis(\"off\")\n",
    "title('unmixing abundance map 3')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,Z = initial_map.shape\n",
    "difference = zeros((X*Y,Z))\n",
    "predicted_first_endmber = zeros((X*Y))\n",
    "\n",
    "first_endmber = initial_map[:,:,0].reshape((X*Y))\n",
    "predicted_first_endmber = predicted_map[:,:,0].reshape((X*Y))\n",
    "\n",
    "for i in range (X*Y):\n",
    "    if first_endmber[i]!= 0:\n",
    "        difference[i,0] = predicted_first_endmber[i]/first_endmber[i] \n",
    "    else:\n",
    "        difference[i,0] = 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_first = difference[:1000,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(difference_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 3]\n",
    "plt.plot(difference_first,'x')\n",
    "plt.ylim(0,10)\n",
    "hlines(1,0,1000,'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"../input/Noise_hypercube/hypercube_20210217_samson_0.05_noise_spitial_check\",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "figure(1)\n",
    "subplot(1,3,1)\n",
    "imshow(a_map[:,:,0], vmin=0, vmax=1)\n",
    "subplot(1,3,2)\n",
    "imshow(a_map[:,:,1], vmin=0, vmax=1)\n",
    "title('Ground Truth Abundance Map')\n",
    "subplot(1,3,3)\n",
    "imshow(a_map[:,:,2], vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "figure(2)\n",
    "subplot(1,3,1)\n",
    "imshow(initial_map[:,:,0], vmin=0, vmax=1)\n",
    "subplot(1,3,2)\n",
    "title('Unmixing Abundance Map')\n",
    "imshow(initial_map[:,:,1], vmin=0, vmax=1)\n",
    "subplot(1,3,3)\n",
    "imshow(initial_map[:,:,2], vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "figure(3)\n",
    "\n",
    "subplot(1,3,1)\n",
    "imshow(predicted_map[:,:,0], vmin=0, vmax=1)\n",
    "subplot(1,3,2)\n",
    "imshow(predicted_map[:,:,1], vmin=0, vmax=1)\n",
    "title('Unmixing Abundance Map after demosaicing')\n",
    "subplot(1,3,3)\n",
    "imshow(predicted_map[:,:,2], vmin=0, vmax=1)\n",
    "\n",
    "figure(4)\n",
    "subplot(1,3,1)\n",
    "imshow(demosaicked[:,:,0], vmin=0, vmax=demosaicked.max())\n",
    "subplot(1,3,2)\n",
    "title('Demosaicing figures')\n",
    "imshow(demosaicked[:,:,1], vmin=0, vmax=demosaicked.max())\n",
    "subplot(1,3,3)\n",
    "imshow(demosaicked[:,:,3], vmin=0, vmax=demosaicked.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
